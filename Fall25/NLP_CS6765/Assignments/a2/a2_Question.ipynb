{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0017c40f-0117-4adb-94ec-8cc43f34a842",
   "metadata": {},
   "source": [
    "# CS4765/6765 Assignment 2: Sentiment Analysis for climate-related text in corporate disclosures\n",
    "\n",
    "We've seen the problem of sentiment analysis in class. In this\n",
    "assignment you will write your own sentiment analysis system. You will\n",
    "implement  two variants of a\n",
    "naive Bayes classifier. The starter code further provides a most-frequent class baseline and logistic regression. You will then compare the various\n",
    "approaches.\n",
    "\n",
    "In this assignment we will consider a three-way sentiment analysis task for climate-related text in corporate disclosures.\n",
    "\n",
    "Read through this notebook in its entirety before getting started. You should only make changes / write code in parts of the notebook where the instructions ask you to do so. These are indicated with TODO throughout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9c799-ff82-4749-950a-41d596b09909",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "I've provided you with the following files for this assignment: `train-sample.csv`, `dev.csv`, `test.csv`.\n",
    "\n",
    "Each of these files is a CSV file. You will use `train-sample.csv` for training models, `dev.csv` for evaluation during model development and for model refinement, and `test.csv` for final evaluation.\n",
    "\n",
    "Each row in each file is an instance consisting of a text, and a label. (Each row also contains an id number, which we won't use in this assignment.) Each text is a climate-related paragraph from an annual report from a company. Each label is 0, 1 or 2. The labels have the following meanings:\n",
    "\n",
    "- 2: Opportunity arising due to climate change (positive sentiment)\n",
    "\n",
    "- 1: Neutral\n",
    "\n",
    "- 0: Risk or threat that negatively impacts an entity (negative sentiment)\n",
    "\n",
    "`train-sample.csv`, `dev.csv`, and `test.csv` contain 800, 200, and 300 instances, respectively.\n",
    "\n",
    "The starter code handles reading these files for you. It also takes care of tokenizing the texts. Do not modify these parts of starter code. You should only modify the starter code where you are instructed to (indicated with TODO).\n",
    "\n",
    "The data for this assignment is from the [ClimateBERT climate sentiment dataset](https://huggingface.co/datasets/climatebert/climate_sentiment). The license is [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) You are of course welcome to read more about this dataset, but it is not necessary to do so to be able to do this assignment. To create the data for this assignment, I converted the original dataset files from parquet to CSV. The original dataset does not include a development set. I randomly split the training data into 80% training and 20% dev to create `train-sample.csv` and `dev.csv`. `test.csv` is the same test data as the original dataset (but formatted as CSV instead of parquet).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8811d3-8bca-4784-ac98-68edd8109065",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "In this assignment you will implement two different approaches to sentiment analysis: multinomial naive Bayes and binary multinomial naive Bayes. The starter code further includes a most-frequent class baseline and logistic regression. Further details on the models are provided below.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Your code must be able to run in the virtual environment on the NLP VM on the lab machines. You must not use NLTK or any other NLP toolkits. You should not import any modules that this notebook does not already import for you. Although the starter code uses an implementation of logistic regression from scikit-learn (sklearn), you must not use scikit-learn for any of the code that you write in this assignment.\n",
    "\n",
    "## Experimental Setup\n",
    "\n",
    "Throughout this assignment, we will always use the training data (`train-sample.csv`) for training models. We will implement our models and then use the development data (`dev.csv`) for preliminary evaluation. Once we've completed this, we will do our final evaluation on the test data (`test.csv`). The starter code guides you through this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cd925-9d7b-4631-b5e6-620ae9b4dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# A simple tokenizer based on the word tokenizer from sklearn.\n",
    "# It applies case folding.\n",
    "word_tokenize_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "def word_tokenize(s, apply_case_folding=True):\n",
    "    return [x.lower() for x in word_tokenize_pattern.findall(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d5db6-4057-4fa5-8dcc-850c397bb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example to demonstrate the tokenization\n",
    "word_tokenize('''This is a sentence. Here is another one! This is to show, just as an example, how \"word_tokenize\" works.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9589e75-1736-4923-b087-156a87cc7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load a data file\n",
    "import csv\n",
    "\n",
    "def get_texts_and_labels(fname):\n",
    "    csv_reader = csv.reader(open(fname))\n",
    "    # Ignore header row\n",
    "    next(csv_reader)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for line in csv_reader:\n",
    "        _,text,label = line\n",
    "        label = int(label)\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "    return texts,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a854659-f7a4-415d-bce3-c120f2b137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and dev data\n",
    "train_texts, train_labels = get_texts_and_labels('data/train-sample.csv')\n",
    "dev_texts, dev_labels = get_texts_and_labels('data/dev.csv')\n",
    "\n",
    "# Some sanity checks\n",
    "assert len(train_texts) == len(train_labels)\n",
    "assert len(dev_texts) == len(dev_labels)\n",
    "\n",
    "for label in train_labels + dev_labels:\n",
    "    assert 0 <= label <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846712-bef5-4c9a-bfcb-0762393f54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# A helper function to print out macro averaged P,R, and F1 and accuracy.\n",
    "# Uses implementantions of evaluation metrics from sklearn.\n",
    "def print_results(gold_labels, predicted_labels):\n",
    "    p,r,f,_ = precision_recall_fscore_support(gold_labels, \n",
    "                                              predicted_labels,\n",
    "                                              average='macro',\n",
    "                                              zero_division=0)\n",
    "    acc = accuracy_score(gold_labels, predicted_labels)\n",
    "\n",
    "    print(\"Precision: \", p)\n",
    "    print(\"Recall: \", r)\n",
    "    print(\"F1: \", f)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd4259-bceb-46d5-b98f-72b430c30892",
   "metadata": {},
   "source": [
    "## Most-frequent Class Baseline\n",
    "\n",
    "The starter code below trains a most-frequent class baseline on the training data and evaluates it on the dev data. (Note that sklearn also includes an implementation of a most-frequent class baseline, which you might find useful for your projects: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a13528-2c51-4313-9660-fb97e994444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A most-frequent class baseline\n",
    "class Baseline:\n",
    "    def __init__(self, labels):\n",
    "        self.train(labels)\n",
    "\n",
    "    def train(self, labels):\n",
    "        # Count classes to determine which is the most frequent\n",
    "        label_freqs = {}\n",
    "        for l in labels:\n",
    "            label_freqs[l] = label_freqs.get(l, 0) + 1\n",
    "        self.mfc = sorted(label_freqs, reverse=True, \n",
    "                          key=lambda x : label_freqs[x])[0]\n",
    "    \n",
    "    def classify(self, test_instance):\n",
    "        # Ignore the test instance and always return the most frequent class\n",
    "        return self.mfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356cf2f-9098-4a9b-87a1-b2fde342d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_classifier = Baseline(train_labels)\n",
    "baseline_dev_predictions = [baseline_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_labels, baseline_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af28db5-9dd5-4b25-af17-6dc7eed2538c",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The implementation below uses the scikit-learn (sklearn) Python module for logistic regression. Scikit-learn is a popular tool for doing many machine learning tasks in Python. It includes implementations of many classifiers (including naive Bayes, but we're implementing that ourselves in this assignment). Read the comments in the code below to learn how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c6c77-8f76-4c94-9e4f-6979e7f18b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn provides functionality for tokenizing text and\n",
    "# extracting features from it. This uses the word_tokenize function\n",
    "# defined above for tokenization, as opposed to sklearn's\n",
    "# default tokenization (although the two are very similar,\n",
    "# except that by default sklearn does not apply case folding).\n",
    "# Using exactly the same tokenization for logistic regression\n",
    "# and for the NB models we will implement enables us to \n",
    "# more easily compare results between the various methods.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "count_vectorizer = CountVectorizer(analyzer=word_tokenize)\n",
    "\n",
    "# train_counts will be a DxV matrix where D is the number of\n",
    "# training documents and V is the number of types in the\n",
    "# training documents. Each cell in the matrix indicates the\n",
    "# frequency (count) of a type in a document.\n",
    "train_counts = count_vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Train a logistic regression classifier on the training\n",
    "# data. A wide range of options are available. sklearn uses\n",
    "# L2 regularization by default. The algorithm for minimizing\n",
    "# the loss during training is LBFGS instead of SGD, which we\n",
    "# saw in lecture.  The maximum number of iterations is set \n",
    "# to 500 (max_iter=500) to allow the model to converge on\n",
    "# this training data. The random_state is set to 0  (an \n",
    "# arbitrarily chosen number) to help ensure results are \n",
    "# consistent from run to run.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "lr = LogisticRegression(max_iter=500,\n",
    "                        random_state=0)\n",
    "lr_classifier = lr.fit(train_counts, train_labels)\n",
    "\n",
    "# Transform the dev documents into a DxV matrix, similar to\n",
    "# that for the training documents, where D is the number of\n",
    "# dev documents, and V is the number of types in the training\n",
    "# documents.\n",
    "dev_counts = count_vectorizer.transform(dev_texts)\n",
    "\n",
    "# Predict the class for each dev document. \n",
    "lr_dev_predictions = lr_classifier.predict(dev_counts)\n",
    "print_results(dev_labels, lr_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c8faa-c407-4c50-a02b-bd467bde8672",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes (6 marks)\n",
    "\n",
    "Implement multinomial naive Bayes, i.e., as described in Appendix B.1-B.3 of the text book. Follow the structure of the starter code provided. Read the comments in the code, and the description below, to understand how it is intended to work.\n",
    "\n",
    "- The constructor, `__init__`, should train the classifier on the provided training data. Similarly to the constructor for `Baseline` above, you might find it useful to have the constructor call helper methods (i.e., `train` in the case of `Baseline`).\n",
    "\n",
    "- `classify` predicts the class for a provided test instance. Be sure to compute probabilities in log space to avoid underflow errors\n",
    "  from multiplying many probabilities.\n",
    "\n",
    "- **Optional:** It can be very helpful to ensure that your probability distributions are actually\n",
    "  probability distributions! You can do this by adding `assert` statements to `sanity_check` to make\n",
    "  sure that all the probabilities you estimate are between 0 and 1,\n",
    "  and that the distributions you estimate sum to 1, e.g., $\\sum_{w \\in\n",
    "  V}P(w|c) = 1$.\n",
    "\n",
    "  You can add further simple checks to your code, for example, `__init__` checks that the number of training documents and classes are the same. You might want to make sure that all the classes you output are `0`, `1`, or `2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd789ca2-7b47-4cdf-b1fd-26abad0302ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NB:\n",
    "\n",
    "    # TODO: Complete this class\n",
    "\n",
    "    def __init__(self, \n",
    "                 documents,\n",
    "                 labels,\n",
    "                 binary=False):\n",
    "        # documents is a list of training documents. You will need to tokenize each document\n",
    "        # labels is a list of corresponding class labels for the training documents (I.e.,\n",
    "        # labels[i] is the class label for document[i]).\n",
    "        # binary indicates whether to use binary multinomial naive Bayes (which you will\n",
    "        # implement in the next step) or (regular) multinomial naive Bayes. You can ignore\n",
    "        # it when you first implement multinomial naive Bayes, and then use it to implement\n",
    "        # binary multinomial naive Bayes after.\n",
    "        assert len(documents) == len(labels)\n",
    "        self.binary = binary\n",
    "         \n",
    "    def sanity_check(self):\n",
    "        # You might want to add some checks here to check that, for example,\n",
    "        # you've estimated valid probability distributions\n",
    "        assert True\n",
    "    \n",
    "    def classify(self, test_instance):\n",
    "        # test_instance is an instance to classify. \n",
    "        # Return the predicted class: must be one of 0, 1, or 2\n",
    "        tokens = word_tokenize(test_instance)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393e08f-6d8a-4129-9f85-b22f101c2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = NB(train_texts, train_labels)\n",
    "nb_classifier.sanity_check()\n",
    "nb_dev_predictions = [nb_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_labels, nb_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf930000-2089-4c5d-a7ca-92581a333a4d",
   "metadata": {},
   "source": [
    "## Binary Multinomial Naive Bayes (1 mark)\n",
    "\n",
    "Also implement binary multinomial naive Bayes (i.e., multinomial naive Bayes with binary features). Recall\n",
    "that in this model, the frequency of a given word in a given document\n",
    "is either 0 (if the word does not occur in the document) or 1 (if the\n",
    "word occurs 1 or more times in the document). Repeated occurrences of\n",
    "a word are ignored. This model is discussed in Appendix B.4 of the text book.\n",
    "\n",
    "Implement this model by adding functionality to the class `NB` for when the value `True` is passed to the constructor for the parameter `binary`. **Hint** This should be a very small amount of additional code. (It's only worth 1 mark!) If you're writing lots of code, you are likely off track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbb727-f029-4b90-9e42-ddda2a81c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bin_classifier = NB(train_texts, train_labels, binary=True)\n",
    "nb_bin_classifier.sanity_check()\n",
    "nb_bin_dev_predictions = [nb_bin_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_labels, nb_bin_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd4cd6-11c9-4937-ac2c-d98787648d70",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "So far, we've only evaluated on the development data. Once you have completed the tasks above (i.e., your implementation of the class `NB`), run the code below to evaluate the classifiers on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4deed-0d23-433d-9e15-7763e86be522",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts,test_labels = get_texts_and_labels('data/test.csv')\n",
    "\n",
    "print(\"Test results:\")\n",
    "print()\n",
    "\n",
    "print(\"Baseline:\")\n",
    "baseline_test_predictions = [baseline_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_labels, baseline_test_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "test_counts = count_vectorizer.transform(test_texts)\n",
    "lr_test_predictions = lr_classifier.predict(test_counts)\n",
    "print_results(test_labels, lr_test_predictions)\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "nb_test_predictions = [nb_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_labels, nb_test_predictions)\n",
    "\n",
    "print(\"Binary Multinomial Naive Bayes:\")\n",
    "nb_bin_test_predictions = [nb_bin_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_labels, nb_bin_test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e20afb-bcab-41c2-8253-6a40ee4ad361",
   "metadata": {},
   "source": [
    "## Report (3 marks)\n",
    "\n",
    "Write a brief report describing the results of the various methods for sentiment analysis considered in this assignment. Address at least the following in your report:\n",
    "\n",
    "1. Does each of logistic regression, multinomial naive Bayes, and binary multinomial naive Bayes outperform the baseline?\n",
    "\n",
    "1. Does logistic regression outperform multinomial naive Bayes?\n",
    "\n",
    "1. Which of multinomial naive Bayes and binary multinomial naive Bayes performs better?\n",
    "\n",
    "1. Which method performs best? Is the relative performance of methods consistent across the dev and test data?\n",
    "\n",
    "1. Carry out some error analysis to attempt to explain what causes the difference in performance between binary multinomial naive Bayes and logistic regression on the test data. For this, you might find it helpful to examine the per-class P, R, and F values, or a confusion matrix. You can do this using `sklearn.metrics.precision_recall_fscore_support` and `sklearn.metrics.confusion_matrix`. You can read the documentation for these functions here:\n",
    "  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "   \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "    I've also included some examples of how to use them below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8380c9-9d9b-4060-bb32-6f9cd8236362",
   "metadata": {},
   "source": [
    "**TODO** Write your report as markdown in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e60ee-8ec7-4043-a55f-58bf2f2c7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO If you need to write extra code to answer question 5 (e.g., to determine \n",
    "# per-class P, R, and F values or to create a confusion matrix) you can put that \n",
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5cace3-927e-4127-9905-f006e69ac826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a confusion matrix for binary NB on the test data. \n",
    "# Note that I've transposed the confusion matrix so that \n",
    "# the rows correspond to system predictions and columns correspond to\n",
    "# gold standard labels, following the convention in the textbook \n",
    "# and class. (By default, sklearn does it the other way around.)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels, nb_bin_test_predictions, labels=[0, 1, 2]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556e728-ce3e-435c-a558-e39e55aa1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculte P, R, F for each class for binary NB on the test data.\n",
    "\n",
    "for label in list(range(3)):\n",
    "    print(label)\n",
    "    # This prints P, R, F, and support (i.e., number of gold standard instances) for each class\n",
    "    print(precision_recall_fscore_support(test_labels, nb_bin_test_predictions, labels=[label]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198b53e-bfc5-4067-8a66-9a81e707a10c",
   "metadata": {},
   "source": [
    "## What to submit\n",
    "\n",
    "When you're done, submit this file to the assignment 2 dropbox on D2L. (You don't need to submit any of the data files we provided you with for this assignment).\n",
    "\n",
    "## Grading\n",
    "\n",
    "Your assignments will be graded based primarily on the correctness of their implementation and the written answers in the report.\n",
    "\n",
    "Assignments that do not conform to the specifications outlined above might not be graded (e.g., modifying parts of the starter code that you were not asked to modify). Assignments that we are unable to run in a reasonable amount of time (less than one minute) also might not be graded. Grades will be out of 10 and broken down as follows:\n",
    "\n",
    "- Multinomial NB: 6\n",
    "\n",
    "- Binary multinomial NB: 1\n",
    "\n",
    "- Report / discussion: 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
