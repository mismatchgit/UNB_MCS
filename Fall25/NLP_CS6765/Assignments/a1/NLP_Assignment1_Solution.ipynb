{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2fae7d75-e9d4-4145-9ea6-d76acf20630b",
      "metadata": {
        "id": "2fae7d75-e9d4-4145-9ea6-d76acf20630b"
      },
      "source": [
        "# CS4765/6765 Assingment 1: Spelling Correction\n",
        "\n",
        "**Due 29 September**\n",
        "\n",
        "In this assignment you will implement a bigram language model and stupid backoff and apply them for the task of spelling correction. (I've taken care of the task of spelling error detection for you.) You will compare your models with a unigram language model.\n",
        "\n",
        "Read through this notebook in its entirety before getting started. You should only make changes / write code in parts of the notebook where the instructions ask you to do so. These are indicated with TODO throughout.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c41fa4-f768-4225-922c-95d6d9de2710",
      "metadata": {
        "id": "71c41fa4-f768-4225-922c-95d6d9de2710"
      },
      "source": [
        "## Data\n",
        "\n",
        "The starter code you have been provided with handles reading the data and tokenization for you. This description is provided to help you to understand how the starter code works and what it is doing.\n",
        "\n",
        "I've provided you with the following additional files for this assignment:\n",
        "\n",
        "- `dev.txt` This is development data that you can use to evaluate your models before submitting them.\n",
        "\n",
        "  This data is a collection of errors in essays by students, taken from the Holbrook Corpus, a well-known spelling error corpus.\n",
        "\n",
        "  Each line of this file represents a sentence that includes exactly 1 spelling error, which has already been identified for you. Each line of this file consists of an integer, followed by a tab, followed by a sentence. The integer represents the (zero-based) index of the token that has been identified as a spelling error in the sentence. For example, in the following sentence:\n",
        "\n",
        "  `2   <s> in tow minutes she was back as jane came in the door he hit her on the back of the head she fell to the ground </s>`\n",
        "\n",
        "  the token at index 2 (tow) is a spelling error. Your job is to correct the indicated spelling errors.\n",
        "\n",
        "  All of the errors that have been identified for correction, and their corrections, consist entirely of alphabetic characters; additionally, the correction is always within edit distance one of the error. (The spelling error detection is imperfect. If you do find other spelling errors in the dataset, you should not attempt to correct them.)\n",
        "\n",
        "  I have applied a simple (regex-based) tokenizer to the sentences, and have eliminated most punctuation.\n",
        "\n",
        "  For this assignment we will tokenize the sentences based on whitespace. I.e., eliminate the initial number and tab, and then split the remaining string based on single whitespace characters. (If you look closely at the data, you’ll see that this tokenization strategy is imperfect. That’s OK for this assignment. Just treat whatever you get from splitting on whitespace as tokens, even if there are some oddities.) The sentences have already been padded with special tokens marking the beginning and end of sentences (`<s>` and `</s>`).\n",
        "\n",
        "  Note that the starter code you have been provided with handles reading the data and tokenization for you. You should not modify these parts of the starter code.\n",
        "\n",
        "- `dev.keys.txt` This file has one word per line; each line is the correction to the spelling error on the corresponding line in `dev.txt`. You will use this file for evaluating your spelling corrector during development.\n",
        "\n",
        "- `test.txt` and `test.keys.txt` This is test data, taken from the same source as the development data, and in the same format. You will use this data for final evaluation of your spelling corrector.\n",
        "\n",
        "- `corpus.txt` A sample of sentences from the Brown Corpus, tokenized in the same manner as `dev.txt`. You will use this corpus to estimate your language models. (This is a rather small corpus, only about 600<i>k</i> words. In practice you would use a much larger corpus to estimate a language model. However, we’re using a small corpus here to keep the computation manageable.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44376bd1-f7f0-4be9-ae77-e3e1c58fea32",
      "metadata": {
        "id": "44376bd1-f7f0-4be9-ae77-e3e1c58fea32"
      },
      "source": [
        "## Models\n",
        "\n",
        "We will use the following model for spelling correction. For a given misspelling $x$, the system's prediction of the correct spelling, $\\hat{w}$, is computed as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{w} = \\mathrm{argmax}_{w \\in C} P(w) \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "where $P(w)$ is the language model, and $C$ is a set of candidate corrections for the misspelling $x$.\n",
        "\n",
        "\n",
        "### Unigram language model\n",
        "\n",
        "The starter code provides a unigram language model. This model does not use any smoothing. Any word that doesn't occur in the training data has probability 0.\n",
        "\n",
        "### Bigram language model\n",
        "\n",
        "Implement a bigram language model with Laplace smoothing. Treat any unknown word as a single word (e.g., UNK) which appears in the training data with frequency 0. (Be sure to account for this UNK type when determining the size of the vocabulary.)\n",
        "\n",
        "Note that in Equation 1 we write $P(w)$ for the language model. Really, though, we’re interested in the probability of the entire sentence, with $w$ replacing $x$. For a bigram language model, a given word instance participates in two bigrams, one with the word before it and one with the word after it. To take this into consideration, we will compute $P(w)$ as below:\n",
        "\n",
        "\\begin{equation}\n",
        "P(w) ≈ P(w_i|w_{i−1})P(w_{i+1}|w_i) \\textrm{ where here } w \\textrm{ is the word at position } i \\ (\\textrm{i.e.}, w_i).\n",
        "\\end{equation}\n",
        "\n",
        "### Stupid Backoff\n",
        "\n",
        "Implement stupid backoff as described in Section 3.6.4 of the textbook. In our case, we will only consider up to the case of bigrams, and so, following the notation in the textbook, we will implement this as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "S(w_i|w_{i-1}) = \\begin{cases}\n",
        "\\frac{\\textrm{count}(w_{i-1} w_i)}{\\textrm{count}(w_{i-1})} & \\textrm{if count}(w_{i-1} w_i) > 0 \\\\\n",
        "\\lambda \\frac{\\textrm{count}(w_i)}{N} & \\textrm{otherwise}\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "where $N$ is the number of token instances (i.e., similarly to the case of the unigram language model).\n",
        "\n",
        "To use stupid backoff in our spelling corrector, we will compute $P(w)$ as below:\n",
        "\n",
        "\\begin{equation}\n",
        "P(w) ≈ S(w_i|w_{i−1})S(w_{i+1}|w_i) \\textrm{ where here } w \\textrm{ is the word at position } i \\ (\\textrm{i.e.}, w_i).\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "### Candidate Corrections\n",
        "\n",
        "For a given misspelling $x$, the set of candidate corrections is all\n",
        "words that are within edit distance 1 of $x$ and in-vocabulary; the\n",
        "vocabulary here is all words (types) in the training corpus\n",
        "(`corpus.txt`). The edit operations are insertion, deletion,\n",
        "substitution, and transposition.\n",
        "\n",
        "Note that the class `CandidateModel` in the starter code below takes care of determining the set of candidate corrections $C$ for a given misspelling $x$ by enumerating all in-vocabulary words that can be arrived at by applying an edit operation to $x$. (An alternative to find all in-vocabulary words within edit distance 1 of $x$ would be to compute the edit distance between $x$ and each word in the vocabulary; however, this approach would tend to be slower.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d48ecaa0-5c2b-4767-8e3b-75e720ff7192",
      "metadata": {
        "id": "d48ecaa0-5c2b-4767-8e3b-75e720ff7192"
      },
      "outputs": [],
      "source": [
        "# A model of candidate in-vocabulary corrections for a spelling error.\n",
        "# See below for an example of how to use it.\n",
        "class CandidateModel:\n",
        "    def __init__(self, train_corpus_fname):\n",
        "        self.ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        self.vocabulary = set()\n",
        "        for line in open(train_corpus_fname):\n",
        "            line = line.split()\n",
        "            # Ignore start and end of sentence markers\n",
        "            words = line[1:len(line) - 1]\n",
        "            for w in words:\n",
        "                self.vocabulary.add(w)\n",
        "\n",
        "    def delete_edits(self, w):\n",
        "        # Return the set of strings that can be formed by applying one\n",
        "        # delete operation to word w\n",
        "        result = []\n",
        "        for i in range(len(w)):\n",
        "            candidate = w[:i] + w[i+1:]\n",
        "            result.append(candidate)\n",
        "        return result\n",
        "\n",
        "    def insert_edits(self, w):\n",
        "        result = []\n",
        "        for i in range(len(w) + 1):\n",
        "            for c in self.ALPHABET:\n",
        "                candidate = w[:i] + c + w[i:]\n",
        "                result.append(candidate)\n",
        "        return result\n",
        "\n",
        "    def transpose_edits(self, w):\n",
        "        result = []\n",
        "        for i in range(1, len(w)):\n",
        "            transposed_letters = w[i] + w[i-1]\n",
        "            candidate = w[:i-1] + transposed_letters + w[i+1:]\n",
        "            result.append(candidate)\n",
        "        return result\n",
        "\n",
        "    def replace_edits(self, w):\n",
        "        result = []\n",
        "        for i in range(len(w)):\n",
        "            for c in self.ALPHABET:\n",
        "                if c != w[i]:\n",
        "                    candidate = w[:i] + c + w[i+1:]\n",
        "                    result.append(candidate)\n",
        "        return result\n",
        "\n",
        "    def candidates(self, w, in_vocabulary=True):\n",
        "        all_candidates = self.delete_edits(w) + self.insert_edits(w) + self.transpose_edits(w) + self.replace_edits(w)\n",
        "        if in_vocabulary:\n",
        "            all_candidates = [x for x in all_candidates if x in self.vocabulary]\n",
        "        return set(all_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0b4e4b42-2348-4a4f-8042-17045fa7fc25",
      "metadata": {
        "id": "0b4e4b42-2348-4a4f-8042-17045fa7fc25"
      },
      "outputs": [],
      "source": [
        "train_fname = 'data/corpus.txt'\n",
        "candidate_model = CandidateModel(train_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b2eebb7-459c-417a-a575-1f44895dea9c",
      "metadata": {
        "id": "8b2eebb7-459c-417a-a575-1f44895dea9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ff1aa8-ec7a-4d6b-9584-d9429dd0f27a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fiend', 'fred', 'freed', 'freud', 'friend', 'rend', 'trend'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# candidate_model can be used to get the set of in-vocabulary candidate corrections for a spelling error.\n",
        "# All candidate corrections are within edit distance one of the spelling error.\n",
        "candidate_model.candidates('frend')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8e1ff0ad-518b-462d-9b6c-8cc4335a338a",
      "metadata": {
        "id": "8e1ff0ad-518b-462d-9b6c-8cc4335a338a"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "EPS = 0.0001\n",
        "\n",
        "# An unsmoothed unigram language model. You should read this to understand how it works.\n",
        "# See examples below of how to use it.\n",
        "class UnsmoothedUnigramLM:\n",
        "    def __init__(self, fname):\n",
        "        self.counts = {}\n",
        "        self.train(fname)\n",
        "\n",
        "    def train(self, fname):\n",
        "        for line in open(fname):\n",
        "            tokens = line.split()\n",
        "            for t in tokens:\n",
        "                self.counts[t] = self.counts.get(t, 0) + 1\n",
        "\n",
        "        # Computing this sum once during training, instead of every\n",
        "        # time it's needed in log_prob, speeds things up\n",
        "        self.num_instances = sum(self.counts.values())\n",
        "\n",
        "    def log_prob(self, word):\n",
        "        # Compute probabilities in log space to avoid underflow errors\n",
        "        # (This is not actually a problem for this language model, but\n",
        "        # it can become an issue when we multiply together many\n",
        "        # probabilities)\n",
        "        if word in self.counts:\n",
        "            return math.log(self.counts[word]) - math.log(self.num_instances)\n",
        "        else:\n",
        "            # This is a bit of a hack to get a float with the value of\n",
        "            # minus infinity for words that have probability 0\n",
        "            return float(\"-inf\")\n",
        "\n",
        "    # These methods might be helpful later for implementing Stupid Backoff\n",
        "    def get_count(self, word):\n",
        "        return self.counts.get(word, 0)\n",
        "\n",
        "    def get_num_instances(self):\n",
        "        return self.num_instances\n",
        "\n",
        "    def check_probs(self):\n",
        "        # Hint: Writing code to check whether the probabilities you\n",
        "        # have computed form a valid probability distribution is very\n",
        "        # helpful, particularly when you start incorporating smoothing\n",
        "        # It can be a bit slow, however, especially for bigram language\n",
        "        # models, so you might want to turn these checks off once\n",
        "        # you're convinced things are working correctly.\n",
        "\n",
        "        # Make sure the probability for each word is between 0 and 1\n",
        "        for w in self.counts:\n",
        "            assert 0 - EPS < math.exp(self.log_prob(w)) < 1 + EPS\n",
        "        # Make sure that the sum of probabilities for all words is 1\n",
        "        assert 1 - EPS < \\\n",
        "            sum([math.exp(self.log_prob(w)) for w in self.counts]) < \\\n",
        "            1 + EPS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd66fb54-4e4d-413b-878a-ec55d056eeb9",
      "metadata": {
        "id": "fd66fb54-4e4d-413b-878a-ec55d056eeb9"
      },
      "outputs": [],
      "source": [
        "# TODO Implement BigramLM following the explanation of the Bigram Language Model above by\n",
        "# completing the constructor and log_prob methods. You are welcome to use additional methods\n",
        "# as needed for your solution, but you should not change the signature for the constructor or\n",
        "# log_prob or check_probs methods because other parts of the starter code (which you shouldn't\n",
        "# modify) rely on these.\n",
        "\n",
        "class BigramLM:\n",
        "    def __init__(self, fname):\n",
        "        # TODO Complete this method\n",
        "        self.counts = {}\n",
        "        self.bigram_counts = {}\n",
        "        self.train(fname)\n",
        "\n",
        "    def train(self, fname):\n",
        "        for line in open(fname):\n",
        "            tokens = line.split()\n",
        "            for i, t in enumerate(tokens):\n",
        "                self.counts[t] = self.counts.get(t, 0) + 1\n",
        "                if i < len(tokens) - 1:\n",
        "                  pair = (tokens[i], tokens[i+1])\n",
        "                  self.bigram_counts[pair] = self.bigram_counts.get(pair, 0) + 1\n",
        "\n",
        "        # Adding UNK to counts explicitly\n",
        "        if \"UNK\" not in self.counts:\n",
        "            self.counts[\"UNK\"] = 0\n",
        "        # Computing this sum once during training, instead of every\n",
        "        # time it's needed in log_prob, speeds things up\n",
        "        # copied the comments also\n",
        "        self.num_instances = sum(self.counts.values())\n",
        "        self.vocab = len(self.counts)\n",
        "\n",
        "        #Print </s> count after training\n",
        "        # print(f\"Count of </s>: {self.counts.get('</s>', 0)}\")\n",
        "\n",
        "    def log_prob(self, w1, w2):\n",
        "        # TODO Complete this method\n",
        "        # This method should return log(P(w2|w1) (using add-1 smoothing)\n",
        "\n",
        "        # Checking to see if the word is known or unknown\n",
        "        w1 = w1 if w1 in self.counts else \"UNK\"\n",
        "        w2 = w2 if w2 in self.counts else \"UNK\"\n",
        "\n",
        "        # Getting counts safely (0 if not present)\n",
        "        bigram_count = self.bigram_counts.get((w1, w2), 0)\n",
        "        unigram_count = self.counts.get(w1, 0)\n",
        "\n",
        "        # Applying Laplace smoothing\n",
        "        return math.log((bigram_count + 1) / (unigram_count + self.vocab))\n",
        "\n",
        "    # Unigram check_probs takes just a second or so but this takes a lot of time\n",
        "    # def check_probs(self):\n",
        "    #     # Hint: Writing code to check whether the probabilities you\n",
        "    #     # have computed form a valid probability distribution is very\n",
        "    #     # helpful, particularly when you start incorporating smoothing\n",
        "    #     # It can be a bit slow, however, especially for bigram language\n",
        "    #     # models, so you might want to turn these checks off once\n",
        "    #     # you're convinced things are working correctly.\n",
        "\n",
        "    #     for w1 in self.counts.keys():\n",
        "    #       if w1 == \"</s>\":  # skip end-of-sentence as w1\n",
        "    #           continue\n",
        "    #       total_prob = 0.0\n",
        "    #       for w2 in self.counts.keys():  # iterate over all possible w2\n",
        "    #           p = math.exp(self.log_prob(w1, w2))\n",
        "    #           assert 0 - EPS < p < 1 + EPS, f\"Probability out of range: P({w2}|{w1})={p}\"\n",
        "    #           total_prob += p\n",
        "    #       assert abs(total_prob - 1.0) < EPS, f\"Probabilities for {w1} do not sum to 1 (sum={total_prob})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "eb89f734-38ee-4cac-92f5-b57b3b049110",
      "metadata": {
        "id": "eb89f734-38ee-4cac-92f5-b57b3b049110"
      },
      "outputs": [],
      "source": [
        "# TODO Implement Stupid Backoff following the explanation of Stupid Backoff above.\n",
        "# Note that you should have the various counts required to do this in unigram_lm\n",
        "# and bigram_lm. As such, your implementation here should be very short. (My\n",
        "# sample solution is about 4 lines. If you're writing a lot of code, you are\n",
        "# likely off track.)\n",
        "\n",
        "def stupid_backoff_score(w1, w2, lmbda):\n",
        "    bigram_prob = bigram_lm.bigram_counts.get((w1, w2), 0) / bigram_lm.counts.get(w1, 1)\n",
        "    unigram_prob = unigram_lm.counts.get(w2, 0) / unigram_lm.num_instances\n",
        "    if bigram_prob > 0:\n",
        "        return bigram_prob\n",
        "    else:\n",
        "        return (lmbda*unigram_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc7781f0-554a-42e6-bde3-14adfdc7c1f4",
      "metadata": {
        "id": "cc7781f0-554a-42e6-bde3-14adfdc7c1f4"
      },
      "outputs": [],
      "source": [
        "# Create and train the language models\n",
        "unigram_lm = UnsmoothedUnigramLM(train_fname)\n",
        "bigram_lm = BigramLM(train_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "446d3243-7133-4132-b111-63dbce3cfb52",
      "metadata": {
        "id": "446d3243-7133-4132-b111-63dbce3cfb52"
      },
      "outputs": [],
      "source": [
        "# You can comment out these lines out to run faster...\n",
        "# unigram_lm.check_probs()\n",
        "# bigram_lm.check_probs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e0cf3e24-3964-4d2c-866a-f2d813adaa25",
      "metadata": {
        "id": "e0cf3e24-3964-4d2c-866a-f2d813adaa25"
      },
      "outputs": [],
      "source": [
        "def get_predictions(predict_dataset_fname, model, stupid_backoff_lambda=1):\n",
        "    # Get the predictions for a model for each instance in a dataset\n",
        "    # model must be 1 of 'unigram', 'bigram', 'stupid'\n",
        "    # stupid_backoff_alpha is only used when model = 'stupid'\n",
        "    corrections = []\n",
        "    for line in open(predict_dataset_fname):\n",
        "        # Split the line on a tab; get the target word to correct and\n",
        "        # the sentence it's in\n",
        "        target_index,sentence = line.split('\\t')\n",
        "        target_index = int(target_index)\n",
        "        sentence = sentence.split()\n",
        "        target_word = sentence[target_index]\n",
        "\n",
        "        # Get the in-vocabulary candidates\n",
        "        iv_candidates = candidate_model.candidates(target_word)\n",
        "\n",
        "        # Find the candidate correction with the highest probability;\n",
        "        # if no candidate has non-zero probability, or there are no\n",
        "        # candidates, give up and output the original target word as\n",
        "        # the correction.\n",
        "        best_prob = float('-inf')\n",
        "        best_correction = target_word\n",
        "        for ivc in sorted(iv_candidates):\n",
        "            if model == 'unigram':\n",
        "                unigram_log_prob = unigram_lm.log_prob(ivc)\n",
        "                ivc_log_prob = unigram_log_prob\n",
        "            elif model == 'bigram':\n",
        "                bigram_log_prob = bigram_lm.log_prob(sentence[target_index - 1], ivc)\n",
        "                bigram_log_prob += bigram_lm.log_prob(ivc, sentence[target_index + 1])\n",
        "                ivc_log_prob = bigram_log_prob\n",
        "            elif model == 'stupid':\n",
        "                # Note that for stupid backoff we're not using log space\n",
        "                ivc_log_prob = stupid_backoff_score(sentence[target_index - 1], ivc, stupid_backoff_lambda)\n",
        "                ivc_log_prob *= stupid_backoff_score(ivc, sentence[target_index + 1], stupid_backoff_lambda)\n",
        "            else:\n",
        "                assert False\n",
        "            if ivc_log_prob > best_prob:\n",
        "                best_prob = ivc_log_prob\n",
        "                best_correction = ivc\n",
        "        corrections.append(best_correction)\n",
        "    return corrections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c0050a8b-90a2-4afd-91ca-76a58da0320b",
      "metadata": {
        "id": "c0050a8b-90a2-4afd-91ca-76a58da0320b"
      },
      "outputs": [],
      "source": [
        "def print_accuracy_for_predictions(predictions, keys):\n",
        "    # If the length of the output and keys are not the same, something went\n",
        "    # wrong...\n",
        "    assert len(predictions) == len(keys)\n",
        "\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    for p,k in zip(predictions,keys):\n",
        "        if p == k:\n",
        "            num_correct += 1\n",
        "        total += 1\n",
        "    accuracy = num_correct / total\n",
        "    print(\"Num correct: \", num_correct)\n",
        "    print(\"Total: \", total)\n",
        "    print(\"Accuracy:\", round(accuracy, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6123ec65-83ee-49d9-b359-2c1b3644d795",
      "metadata": {
        "id": "6123ec65-83ee-49d9-b359-2c1b3644d795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086ad6b6-5d68-42bf-f783-ff379fda19f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram:\n",
            "Num correct:  175\n",
            "Total:  421\n",
            "Accuracy: 0.416\n",
            "\n",
            "Bigram:\n",
            "Num correct:  242\n",
            "Total:  421\n",
            "Accuracy: 0.575\n",
            "\n",
            "Stupid backoff:\n",
            "Num correct:  244\n",
            "Total:  421\n",
            "Accuracy: 0.58\n"
          ]
        }
      ],
      "source": [
        "dev_fname = 'data/dev.txt'\n",
        "unigram_dev_predictions = get_predictions(dev_fname, 'unigram')\n",
        "bigram_dev_predictions = get_predictions(dev_fname, 'bigram')\n",
        "# The third argument to get_predictions is the weight for stupid backoff\n",
        "# (lambda in Eqation 3.31 in the textbook)\n",
        "stupid_dev_predictions = get_predictions(dev_fname, 'stupid', 1)\n",
        "\n",
        "dev_keys_fname = 'data/dev.keys.txt'\n",
        "dev_keys = [x.strip() for x in open(dev_keys_fname)]\n",
        "\n",
        "print('Unigram:')\n",
        "print_accuracy_for_predictions(unigram_dev_predictions, dev_keys)\n",
        "\n",
        "print()\n",
        "print('Bigram:')\n",
        "print_accuracy_for_predictions(bigram_dev_predictions, dev_keys)\n",
        "\n",
        "print()\n",
        "print('Stupid backoff:')\n",
        "print_accuracy_for_predictions(stupid_dev_predictions, dev_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd60fa3-7a82-4272-a7a9-666d31832440",
      "metadata": {
        "id": "7dd60fa3-7a82-4272-a7a9-666d31832440"
      },
      "source": [
        "The code above uses stupid backoff with a single value for lambda (1). Your task here is to find a good value for lambda. We will discuss approaches for doing this in lecture. Importantly, you must only consider the development data (and crucially not the test data) when doing so."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "best_lambda = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "for lmbda in np.arange(0.05, 1.05, 0.05):\n",
        "    stupid_dev_predictions = get_predictions(dev_fname, 'stupid', lmbda)\n",
        "    print(f'\\nStupid backoff (λ={lmbda:.2f}):')\n",
        "    # just printing the accuracy for visualization\n",
        "    print_accuracy_for_predictions(stupid_dev_predictions, dev_keys)\n",
        "\n",
        "    # Computing accuracy manually (since I can't modify the \"print_accuracy_for_predictions\" function)\n",
        "    num_correct = sum([p == k for p, k in zip(stupid_dev_predictions, dev_keys)])\n",
        "    accuracy = num_correct / len(dev_keys)\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_lambda = lmbda\n",
        "\n",
        "print(f\"\\nBest λ = {best_lambda:.2f} with Accuracy = {round(best_accuracy, 3)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13C3MdMBXU7W",
        "outputId": "3988742d-03a5-4ba1-a038-0f04a06e4c10"
      },
      "id": "13C3MdMBXU7W",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stupid backoff (λ=0.05):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.10):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.15):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.20):\n",
            "Num correct:  244\n",
            "Total:  421\n",
            "Accuracy: 0.58\n",
            "\n",
            "Stupid backoff (λ=0.25):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.30):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.35):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.40):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.45):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.50):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.55):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.60):\n",
            "Num correct:  246\n",
            "Total:  421\n",
            "Accuracy: 0.584\n",
            "\n",
            "Stupid backoff (λ=0.65):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.70):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.75):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.80):\n",
            "Num correct:  244\n",
            "Total:  421\n",
            "Accuracy: 0.58\n",
            "\n",
            "Stupid backoff (λ=0.85):\n",
            "Num correct:  245\n",
            "Total:  421\n",
            "Accuracy: 0.582\n",
            "\n",
            "Stupid backoff (λ=0.90):\n",
            "Num correct:  244\n",
            "Total:  421\n",
            "Accuracy: 0.58\n",
            "\n",
            "Stupid backoff (λ=0.95):\n",
            "Num correct:  243\n",
            "Total:  421\n",
            "Accuracy: 0.577\n",
            "\n",
            "Stupid backoff (λ=1.00):\n",
            "Num correct:  244\n",
            "Total:  421\n",
            "Accuracy: 0.58\n",
            "\n",
            "Best λ = 0.25 with Accuracy = 0.584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d6afa773-835d-4a55-aad6-2ccc27758982",
      "metadata": {
        "id": "d6afa773-835d-4a55-aad6-2ccc27758982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98a4866-c750-4b59-a115-b297363e6c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram:\n",
            "Num correct:  140\n",
            "Total:  332\n",
            "Accuracy: 0.422\n",
            "\n",
            "Bigram:\n",
            "Num correct:  179\n",
            "Total:  332\n",
            "Accuracy: 0.539\n",
            "\n",
            "Stupid backoff:\n",
            "Num correct:  196\n",
            "Total:  332\n",
            "Accuracy: 0.59\n"
          ]
        }
      ],
      "source": [
        "# When you are done all of the parts above, evaluate the models on the test data by running this cell.\n",
        "# Note that you should set the value of BEST_LAMBDA to whatever value you selected over the dev data above.\n",
        "test_fname = 'data/test.txt'\n",
        "unigram_test_predictions = get_predictions(test_fname, 'unigram')\n",
        "bigram_test_predictions = get_predictions(test_fname, 'bigram')\n",
        "\n",
        "BEST_LAMBDA = .25\n",
        "stupid_test_predictions = get_predictions(test_fname, 'stupid', BEST_LAMBDA)\n",
        "\n",
        "test_keys_fname = 'data/test.keys.txt'\n",
        "test_keys = [x.strip() for x in open(test_keys_fname)]\n",
        "\n",
        "print('Unigram:')\n",
        "print_accuracy_for_predictions(unigram_test_predictions, test_keys)\n",
        "\n",
        "print()\n",
        "print('Bigram:')\n",
        "print_accuracy_for_predictions(bigram_test_predictions, test_keys)\n",
        "\n",
        "print()\n",
        "print('Stupid backoff:')\n",
        "print_accuracy_for_predictions(stupid_test_predictions, test_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eabc43eb-a888-4fa2-bce1-0b353e2a60bd",
      "metadata": {
        "id": "eabc43eb-a888-4fa2-bce1-0b353e2a60bd"
      },
      "source": [
        "## Report\n",
        "\n",
        "Write a report addressing at least the following points:\n",
        "\n",
        "1. Compare the 3 models (unigram, bigram, and stupid backoff). Which model performs best? Is the relative performance of the models consistent across the development and test data?\n",
        "\n",
        "1. For whichever model you find to perform best, why do you believe it performs better than the others? Justify your answer?\n",
        "\n",
        "1. Clearly describe the process that you used to select the best value for lambda. What value of lambda did you find to work best?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f206b0af-9098-423e-88a8-1b95227c6a62",
      "metadata": {
        "id": "f206b0af-9098-423e-88a8-1b95227c6a62"
      },
      "source": [
        "#### **Report**\n",
        "\n",
        "\n",
        "#### **1. Compare the 3 models (unigram, bigram, and stupid backoff). Which model performs best? Is the relative performance of the models consistent across the development and test data?**\n",
        "\n",
        "I evaluated three language models — **Unigram**, **Bigram**, and **Stupid Backoff** — on both the development and test datasets.  \n",
        "After tuning λ for the Stupid Backoff model, the best performance was achieved at **λ = 0.25**.  \n",
        "The results are summarized below:\n",
        "\n",
        "| Model           | Dev Accuracy | Test Accuracy |\n",
        "|-----------------|-------------|--------------|\n",
        "| **Unigram**     | 0.416       | 0.422        |\n",
        "| **Bigram**      | 0.575       | 0.539        |\n",
        "| **Stupid Backoff** (λ = 0.25) | **0.584** | **0.590** |\n",
        "\n",
        "**Observations:**  \n",
        "- The **Stupid Backoff model** achieves the highest accuracy on both development and test datasets.  \n",
        "- The relative performance order (**Stupid Backoff > Bigram > Unigram**) remains **consistent across both datasets**, indicating that the improvement is robust.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. For whichever model you find to perform best, why do you believe it performs better than the others? Justify your answer?**\n",
        "\n",
        "The Stupid Backoff model outperforms the others because:  \n",
        "\n",
        "- It **uses bigram probabilities when available**, effectively capturing local word dependencies.  \n",
        "- For unseen bigrams, it **backs off to a scaled unigram counting (denoted by S)**, preventing zero-probability issues.  \n",
        "- This hybrid approach ensures better coverage for rare word pairs while still leveraging context for frequent ones.  \n",
        "\n",
        "Thus, Stupid Backoff strikes the best balance between **context sensitivity** and **generalization**, resulting in superior accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Clearly describe the process that you used to select the best value for lambda. What value of lambda did you find to work best?**\n",
        "\n",
        "To select the best value of λ for the Stupid Backoff model, I performed a **grid search** over the interval **[0.05, 1.0]** with a step size of **0.05**.  \n",
        "For each λ, I:\n",
        "\n",
        "1. Computed predictions on the development set using the `get_predictions` function.\n",
        "2. Measured accuracy using `print_accuracy_for_predictions`.\n",
        "3. Compared the accuracy with the best accuracy found so far and updated the best λ if performance improved.\n",
        "4. Though I found Multiple values yielding the highest accuracy but according to the logic I used(if the accuracy is not grater then it won't update the value of lambda) the initial value that got the highest score was chosen.\n",
        "\n",
        "**Observations:**  \n",
        "\n",
        "I observed that **multiple λ values** (0.25, 0.30, 0.35, 0.45, 0.50, 0.60) all achieved the **same highest accuracy of 0.584** on the development set.\n",
        "This indicates that the Stupid Backoff model is relatively **insensitive to λ within this range**, as scaling the unigram probability slightly more or less does not significantly change which predictions are correct."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96acf6e8-324c-4968-9a0e-683ac38fa144",
      "metadata": {
        "id": "96acf6e8-324c-4968-9a0e-683ac38fa144"
      },
      "source": [
        "## What to submit\n",
        "\n",
        "When you're done, submit this file to the assignment 1 dropbox on D2L. (You don't need to submit any of the data files we provided you with for this assignment).\n",
        "\n",
        "## Grading\n",
        "\n",
        "Your assignments will be graded based primarily on the correctness of their implementation and the written answers in the report.\n",
        "\n",
        "Assignments that do not conform to the specifications outlined above might not be graded (e.g., modifying parts of the starter code that you were not asked to modify). Assignments that we are unable to run in a reasonable amount of time (less than one minute) also might not be graded. Grades will be out of 10 and broken down as follows:\n",
        "\n",
        "- Bigram LM: 5\n",
        "\n",
        "- Stupid Backoff: 2\n",
        "\n",
        "- Report / discussion: 3\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}