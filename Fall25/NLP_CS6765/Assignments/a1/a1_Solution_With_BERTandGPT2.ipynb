{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fae7d75-e9d4-4145-9ea6-d76acf20630b",
   "metadata": {},
   "source": [
    "# CS4765/6765 Assignment 1: Spelling Correction (with BERT and GPT2)\n",
    "\n",
    "Here is an example of how BERT and GPT2 can be applied to the spelling correction task from assignment 1. BERT is a masked language model and was the state-of-the-art for many NLP tasks in ~2019. GPT2 is an autoregressive language model and was the pre-cursor to GPT3 and ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6994339-436a-4fd7-b1e8-6c7de51b3d41",
   "metadata": {},
   "source": [
    "## Candidate model\n",
    "\n",
    "We use the same candidate model as for assignment 1. The code in this section is taken straight from the assignment 1 starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48ecaa0-5c2b-4767-8e3b-75e720ff7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model of candidate in-vocabulary corrections for a spelling error.\n",
    "# See below for an example of how to use it.\n",
    "class CandidateModel:\n",
    "    def __init__(self, train_corpus_fname):\n",
    "        self.ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        self.vocabulary = set()\n",
    "        for line in open(train_corpus_fname):\n",
    "            line = line.split()\n",
    "            # Ignore start and end of sentence markers\n",
    "            words = line[1:len(line) - 1]\n",
    "            for w in words:\n",
    "                self.vocabulary.add(w)\n",
    "\n",
    "    def delete_edits(self, w):\n",
    "        # Return the set of strings that can be formed by applying one\n",
    "        # delete operation to word w\n",
    "        result = []\n",
    "        for i in range(len(w)):\n",
    "            candidate = w[:i] + w[i+1:]\n",
    "            result.append(candidate)\n",
    "        return result\n",
    "\n",
    "    def insert_edits(self, w):\n",
    "        result = []\n",
    "        for i in range(len(w) + 1):\n",
    "            for c in self.ALPHABET:\n",
    "                candidate = w[:i] + c + w[i:]\n",
    "                result.append(candidate)\n",
    "        return result\n",
    "\n",
    "    def transpose_edits(self, w):\n",
    "        result = []\n",
    "        for i in range(1, len(w)):\n",
    "            transposed_letters = w[i] + w[i-1]\n",
    "            candidate = w[:i-1] + transposed_letters + w[i+1:]\n",
    "            result.append(candidate)\n",
    "        return result\n",
    "\n",
    "    def replace_edits(self, w):\n",
    "        result = []\n",
    "        for i in range(len(w)):\n",
    "            for c in self.ALPHABET:\n",
    "                if c != w[i]:\n",
    "                    candidate = w[:i] + c + w[i+1:]\n",
    "                    result.append(candidate)\n",
    "        return result\n",
    "\n",
    "    def candidates(self, w, in_vocabulary=True):\n",
    "        all_candidates = self.delete_edits(w) + self.insert_edits(w) + self.transpose_edits(w) + self.replace_edits(w)\n",
    "        if in_vocabulary:\n",
    "            all_candidates = [x for x in all_candidates if x in self.vocabulary]\n",
    "        return set(all_candidates)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4e4b42-2348-4a4f-8042-17045fa7fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = 'data/corpus.txt'\n",
    "candidate_model = CandidateModel(train_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2eebb7-459c-417a-a575-1f44895dea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fiend', 'fred', 'freed', 'freud', 'friend', 'rend', 'trend'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# candidate_model can be used to get the set of in-vocabulary candidate corrections for a spelling error.\n",
    "# All candidate corrections are within edit distance one of the spelling error.\n",
    "candidate_model.candidates('frend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0050a8b-90a2-4afd-91ca-76a58da0320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_for_predictions(predictions, keys):\n",
    "    # If the length of the output and keys are not the same, something went\n",
    "    # wrong...\n",
    "    assert len(predictions) == len(keys)\n",
    "\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    for p,k in zip(predictions,keys):\n",
    "        if p == k:\n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    accuracy = num_correct / total\n",
    "    print(\"Num correct: \", num_correct)\n",
    "    print(\"Total: \", total)\n",
    "    print(\"Accuracy:\", round(accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465f88da-32c4-4098-989e-6765d0f6b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_fname = 'data/dev.txt'\n",
    "dev_keys_fname = 'data/dev.keys.txt'\n",
    "dev_keys = [x.strip() for x in open(dev_keys_fname)]\n",
    "\n",
    "test_fname = 'data/test.txt'\n",
    "test_keys_fname = 'data/test.keys.txt'\n",
    "test_keys = [x.strip() for x in open(test_keys_fname)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5dcf7-85aa-4ccd-9bf3-6c6c43459314",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "This example of applying BERT to spelling correction uses a HuggingFace pipeline and attempts to emphasize simplicity in implementation. It replaces the target word to correct by [MASK] and then uses a fill-mask pipeline to get the top-100 predicted words from BERT for this mask. It then filters these predicted words to include only those that are also among the in-vocabulary candidate corrections from the candidate model. The highest scoring word (according to BERT) remaining after this filtering is returned as the predicted correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a80df11-5e2b-4d55-82dd-ca26b1257510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "bert_unmasker = pipeline('fill-mask', model='distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90af7c5f-7689-4946-abdd-f7c892c71c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_prediction(line):\n",
    "    # Split the line on a tab; get the target word to correct and\n",
    "    # the sentence it's in\n",
    "    target_index,sentence = line.split('\\t')\n",
    "    target_index = int(target_index)\n",
    "    sentence = sentence.split()\n",
    "    target_word = sentence[target_index]\n",
    "\n",
    "    # Get the in-vocabulary candidates \n",
    "    iv_candidates = candidate_model.candidates(target_word)\n",
    "\n",
    "    masked_sentence = list(sentence)\n",
    "    masked_sentence[target_index] = \"[MASK]\"\n",
    "    masked_sentence = \" \".join(masked_sentence)\n",
    "\n",
    "    # Here we only get the top 100 predictions from BERT. To get predictions for \n",
    "    # all items in the vocabulary, we could set top_k to the vocab size, in\n",
    "    # this case 30522 (see the commented out line of code below). This would allow\n",
    "    # the spelling correction to consider more possible corrections and potentially\n",
    "    # achieve a higher accuracy, but this slows things down quite a bit.\n",
    "    predictions = bert_unmasker(masked_sentence, top_k=100)\n",
    "    predictions = [x for x in predictions if x['token_str'] in iv_candidates]\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        return sentence[target_index]\n",
    "    else: \n",
    "        return predictions[0]['token_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231b8f8c-b71f-447f-870a-45678a62bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_predictions(predict_dataset_fname):\n",
    "    predictions = []\n",
    "    for line in open(predict_dataset_fname):\n",
    "        curr_prediction = get_bert_prediction(line)\n",
    "        predictions.append(curr_prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09a10c9-1287-4581-96ab-c36617fd3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dev_predictions = get_bert_predictions(dev_fname)\n",
    "bert_test_predictions = get_bert_predictions(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16ce5d3-799e-4aab-b886-424c76a0be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:\n",
      "Dev:\n",
      "Num correct:  321\n",
      "Total:  421\n",
      "Accuracy: 0.762\n",
      "\n",
      "Test:\n",
      "Num correct:  238\n",
      "Total:  332\n",
      "Accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "print('BERT:')\n",
    "print('Dev:')\n",
    "print_accuracy_for_predictions(bert_dev_predictions, dev_keys)\n",
    "\n",
    "print()\n",
    "print('Test:')\n",
    "print_accuracy_for_predictions(bert_test_predictions, test_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c3b120-d892-4fc5-8e29-b51c9b69f13a",
   "metadata": {},
   "source": [
    "## GPT-2\n",
    "\n",
    "This application of GPT-2 to spelling correction takes the following approach. For each in-vocabulary candidate correction from the candidate model, do the following:\n",
    "\n",
    "- substitute the target word to correct with the candidate\n",
    "- determine the loss for the resulting sentence\n",
    "\n",
    "Then return the best candidate correction (i.e., the candidate correction with the lowest loss).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed465f14-8d9a-4aa1-8e11-58adbb7f7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47496bca-f34d-41f2-a015-178ca030eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpt_prediction(line):\n",
    "    # Select the in-vocabulary candidate that gives lowest loss when\n",
    "    # substituted for the target word in the sentence. We could get \n",
    "    # the probability instead, but for this demo it seemed easier\n",
    "    # to use the loss.\n",
    "    \n",
    "    target_index,sentence = line.split('\\t')\n",
    "    target_index = int(target_index)\n",
    "    sentence = sentence.split()\n",
    "    target_word = sentence[target_index]\n",
    "    \n",
    "    # Get the in-vocabulary candidates \n",
    "    iv_candidates = candidate_model.candidates(target_word)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_correction = sentence[target_index]\n",
    "    for iv_candidate in iv_candidates:\n",
    "        sentence_with_candidate = list(sentence)\n",
    "        sentence_with_candidate[target_index] = iv_candidate\n",
    "        sentence_with_candidate = \" \".join(sentence_with_candidate)\n",
    "\n",
    "        inputs = tokenizer(sentence_with_candidate, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss.item()\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_correction = iv_candidate\n",
    "\n",
    "    return best_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9916246-1f4f-4b6b-b1f5-8671b3664143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_predictions(predict_dataset_fname):\n",
    "    predictions = []\n",
    "    for line in open(predict_dataset_fname):\n",
    "        curr_prediction = get_gpt_prediction(line)\n",
    "        predictions.append(curr_prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aebf1ab-e799-4107-b526-8325f7bb2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "gpt_dev_predictions = get_gpt_predictions(dev_fname)\n",
    "gpt_test_predictions = get_gpt_predictions(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5c61f56-fb5f-4733-90ec-e6fd1ae68bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Dev:\n",
      "Num correct:  346\n",
      "Total:  421\n",
      "Accuracy: 0.822\n",
      "\n",
      "Test:\n",
      "Num correct:  266\n",
      "Total:  332\n",
      "Accuracy: 0.801\n"
     ]
    }
   ],
   "source": [
    "print('GPT:')\n",
    "print('Dev:')\n",
    "print_accuracy_for_predictions(gpt_dev_predictions, dev_keys)\n",
    "\n",
    "print()\n",
    "print('Test:')\n",
    "print_accuracy_for_predictions(gpt_test_predictions, test_keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
